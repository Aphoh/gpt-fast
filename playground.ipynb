{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/server24/will_workspace/gpt-fast/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigcode/starcoder2-3b\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\"./checkpoints/bigcode/starcoder2-3b\", torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ModelArgs, Transformer\n",
    "from util import load_model\n",
    "from pathlib import Path\n",
    "\n",
    "ckpt_path = Path(\"./checkpoints/bigcode/starcoder2-3b/model.pth\")\n",
    "with torch.device(\"meta\"):\n",
    "    model = Transformer.from_name(ckpt_path.parent.name)\n",
    "model = load_model(model, \"./checkpoints/bigcode/starcoder2-3b/model.pth\", device=\"cuda\", precision=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.0312, -0.1787,  1.3203,  ..., -3.7969, -2.5469, -1.5000],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.attention.flex_attention import create_block_mask\n",
    "\n",
    "def causal_mask(b, h, q_idx, kv_idx):\n",
    "    return q_idx >= kv_idx\n",
    "\n",
    "\n",
    "def prefill(model: Transformer, x: torch.Tensor, input_pos: torch.Tensor, **sampling_kwargs) -> torch.Tensor:\n",
    "    # input_pos: [B, S]\n",
    "    mask = create_block_mask(causal_mask, 1, 1, input_pos.shape[0], model.max_seq_length, device=x.device)\n",
    "    logits = model(mask, x, input_pos)\n",
    "    return logits\n",
    "\n",
    "device = torch.device('cuda')\n",
    "with device:\n",
    "    with torch.inference_mode():\n",
    "        input_ids = tokenizer.encode(\"def foo(x):\")\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "        input_pos = torch.arange(input_ids.shape[1])\n",
    "        model.setup_caches(1, 4096)\n",
    "        logits = prefill(model, input_ids, input_pos)\n",
    "logits[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.1953, -0.0202,  1.5137,  ..., -3.6777, -2.3906, -1.3330],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    hf_logits = hf_model(input_ids).logits\n",
    "hf_logits[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1064, -0.0704, -0.0350,  0.0284,  0.3872,  0.0245, -0.0554, -0.0607,\n",
       "        -0.0540, -0.0268,  0.0265,  0.0748, -0.0239, -0.0193, -0.0831,  0.0295,\n",
       "         0.0307,  0.0203,  0.0144, -0.0967,  0.0245,  0.0349,  0.0264,  0.0864,\n",
       "         0.0653,  0.0370,  0.0433, -0.0028,  0.0972, -0.0634,  0.0167, -0.0210,\n",
       "        -0.0120,  0.0177, -0.0409, -0.0268, -0.0420,  0.0989,  0.0662,  0.0100,\n",
       "         0.0153,  0.0403,  0.0277,  0.0042,  0.0643,  0.0005, -0.0150,  0.0175,\n",
       "        -0.0486,  0.0706, -0.0342,  0.0209,  0.0337, -0.0156, -0.0322, -0.0441,\n",
       "         0.0263,  0.0255,  0.0206,  0.0764,  0.4221,  0.0052,  0.1537,  0.0377,\n",
       "         0.0268,  0.0210, -0.0186, -0.0291, -0.0569, -0.0666,  0.0228, -0.0198,\n",
       "         0.0040, -0.0020,  0.0191, -0.0294, -0.0268, -0.0848, -0.1925, -0.0322,\n",
       "         0.0199, -0.0363, -0.0210,  0.0505, -0.4062,  0.0842,  0.0570,  0.0236,\n",
       "        -0.0049, -0.0291,  0.0443, -0.0729,  0.0069,  0.0616,  0.0599,  0.1005,\n",
       "        -0.0626,  0.0480, -0.0148,  0.0519, -0.0674, -0.0040,  0.0613, -0.0272,\n",
       "        -0.0100, -0.0420, -0.0715,  0.0031,  0.0429,  0.0124, -0.0455, -0.0195,\n",
       "        -0.0801,  0.0831,  0.0601,  0.0173,  0.0381, -0.0224, -0.0140, -0.0345,\n",
       "         0.0137,  0.0068, -0.0126, -0.2920, -0.0608, -0.0167,  0.0358,  0.0008,\n",
       "        -0.0016, -0.0432, -0.0571,  0.0281,  0.0007,  0.0014,  0.0119, -0.0327,\n",
       "         0.0189, -0.0085, -0.0017,  0.0072, -0.0130, -0.0162,  0.0125,  0.0222,\n",
       "         0.0298, -0.0120,  0.0123,  0.0006,  0.0346, -0.0040, -0.0242, -0.0130,\n",
       "        -0.0670,  0.0185,  0.0225, -0.0161,  0.0161,  0.0079,  0.0030,  0.0141,\n",
       "         0.0196,  0.0228, -0.0098,  0.0106, -0.0125, -0.0094, -0.0333, -0.0080,\n",
       "         0.0123,  0.0770,  0.0232, -0.0069,  0.0236, -0.0052,  0.0230,  0.0298,\n",
       "         0.0161, -0.0039, -0.0384, -0.0268, -0.0315, -0.0235, -0.0130,  0.0103,\n",
       "         0.0353,  0.0038, -0.0483, -0.0179, -0.0039,  0.0120,  0.0225,  0.0099,\n",
       "         0.0269, -0.0224, -0.0094, -0.0134,  0.0423,  0.1580, -0.0035,  0.0073,\n",
       "         0.0184,  0.0238, -0.0186,  0.0144, -0.0459,  0.0223,  0.0145,  0.0411,\n",
       "         0.0032, -0.0205, -0.0173,  0.0031,  0.0022,  0.0250,  0.0084,  0.0054,\n",
       "         0.0057,  0.0236, -0.0157,  0.0141,  0.0211,  0.0664, -0.0145,  0.0159,\n",
       "         0.0018,  0.0102,  0.0261,  0.0408, -0.0029,  0.0526,  0.0326,  0.0351,\n",
       "         0.0245, -0.0457, -0.0054,  0.0325, -0.0171,  0.1247,  0.0283,  0.0619,\n",
       "        -0.0071,  0.0031,  0.0356,  0.0090,  0.0328,  0.0221, -0.0420, -0.0291,\n",
       "        -0.0068, -0.0712,  0.0097, -0.0258,  0.0026,  0.0142,  0.0021,  0.0315],\n",
       "       device='cuda:0', dtype=torch.float16, requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_model.model.layers[0].self_attn.v_proj.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1333213819.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    model.layers[0].attention.wqkv.bias[]\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].attention.wqkv.bias[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
